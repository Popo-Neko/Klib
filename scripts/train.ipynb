{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models.model import Model\n",
    "from models.utils import Tokenizer, TextClassificationDataset, train_val_split, get_loader\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils import accuracy\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### data -> tokenizer -> encoding -> dataset -> dataloader ###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### data ###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# 1. 准备数据集\n",
    "train_data_path = \"../data/train_data4type(utf-8).csv\"\n",
    "test_data_path = \"../data/test_data4type(ansi).csv\"\n",
    "df_train = pd.read_csv(train_data_path, encoding='utf-8')\n",
    "df_test = pd.read_csv(test_data_path, encoding='ansi')\n",
    "train_X, train_y = list(df_train['combinedText']), list(df_train['type'])\n",
    "test_X, test_y = list(df_test['combinedText']), list(df_test['type'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tokenizer -> encoding ###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "train_text, val_text, train_labels, val_labels = train_val_split(train_X, train_y)\n",
    "test_text, _, test_labels, _ = train_val_split(test_X, test_y, test_size=0)\n",
    "train_encodings = tokenizer(train_text)\n",
    "val_encodings = tokenizer(val_text)\n",
    "test_encodings = tokenizer(test_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### encoding -> dataset -> dataloader ###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "train_dataset = TextClassificationDataset(encodings=train_encodings, labels=train_labels)\n",
    "val_dataset = TextClassificationDataset(encodings=val_encodings, labels=val_labels)\n",
    "test_dataset = TextClassificationDataset(encodings=test_encodings, labels=test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model -> train_loop ###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../models/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Model(model_path=\"../models/bert-base-chinese\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def train(train_dataset, val_dataset, model, batch_size, num_epochs, checkpoint=False, step=100, learning_rate=1e-5):\n",
    "    # DataLoader\n",
    "    train_loader = get_loader(train_dataset, batch_size)\n",
    "    val_loader = get_loader(val_dataset, batch_size)\n",
    "\n",
    "    # device\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # Model\n",
    "    if checkpoint is not False:\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Optimizer\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # SummaryWriter\n",
    "    datetime_str = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "    logs_path = \"logs/\" + datetime_str\n",
    "    writer1 = SummaryWriter(f\"{logs_path}/train_loss\")\n",
    "    writer2 = SummaryWriter(f\"{logs_path}/test_loss\")\n",
    "    writer3 = SummaryWriter(f\"{logs_path}/train_acc\")\n",
    "    writer4 = SummaryWriter(f\"{logs_path}/test_acc\")\n",
    "\n",
    "    # train_loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for i, batch in tqdm(enumerate(train_loader), total=int(len(train_dataset)/batch_size)):\n",
    "            if i % 1 == 0:\n",
    "                checkpoint_name = f'model_checkpoint_utf8_{i}.pth'\n",
    "                torch.save(model.state_dict(), os.path.join(r'../models/checkpoints', checkpoint_name))\n",
    "            if i > step:\n",
    "                break\n",
    "            optim.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            with torch.no_grad():\n",
    "                logits = outputs.logits\n",
    "                train_acc = accuracy(logits, labels)\n",
    "                writer1.add_scalar(\"loss-step-train\", loss, i)\n",
    "                writer3.add_scalar(\"acc-step-train\", train_acc, i)\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for i, batch in tqdm(enumerate(val_loader), total=int(len(val_dataset)/batch_size)):\n",
    "                if i > step:\n",
    "                    break\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits\n",
    "                test_acc = accuracy(logits, labels)\n",
    "                writer2.add_scalar(\"loss-step-test\", loss, i)\n",
    "                writer4.add_scalar(\"acc-step-test\", test_acc, i)\n",
    "    writer1.close()\n",
    "    writer2.close()\n",
    "    writer3.close()\n",
    "    writer4.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [01:17,  1.53s/it]\n",
      "51it [00:13,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "train(train_dataset, val_dataset, model, 16, 1, False, 50, 1e-5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### inference ###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def inference4acc(test_dataset, model, checkpoint_file_path, batch_size, shuffle=True):\n",
    "    # loader\n",
    "    test_loader = get_loader(test_dataset, batch_size, shuffle)\n",
    "\n",
    "    # device\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # load model\n",
    "    checkpoint_file = checkpoint_file_path\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # inference\n",
    "    predictions, targets= [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predicted_labels = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(predicted_labels.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    predictions = torch.tensor(predictions)\n",
    "    targets = torch.tensor(targets)\n",
    "    acc = accuracy(predictions, targets)\n",
    "\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290/290 [01:02<00:00,  4.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8422303868597363"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference4acc(test_dataset, model, f\"../models/checkpoints/model_checkpoint_utf8_{40}.pth\", 16)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290/290 [01:14<00:00,  3.90it/s]\n",
      "100%|██████████| 290/290 [01:08<00:00,  4.21it/s]\n",
      "100%|██████████| 290/290 [01:01<00:00,  4.69it/s]\n",
      "100%|██████████| 290/290 [01:02<00:00,  4.68it/s]\n",
      "100%|██████████| 290/290 [01:02<00:00,  4.67it/s]\n",
      "100%|██████████| 290/290 [01:02<00:00,  4.67it/s]\n",
      "100%|██████████| 290/290 [01:01<00:00,  4.69it/s]\n",
      "100%|██████████| 290/290 [01:01<00:00,  4.69it/s]\n",
      "100%|██████████| 290/290 [01:01<00:00,  4.68it/s]\n",
      "100%|██████████| 290/290 [01:02<00:00,  4.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6211368057056408"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1, sum= [], 0\n",
    "# model = Model()\n",
    "for i in [str(i*1) for i in range(1, 11)]:\n",
    "    l1.append(inference4acc(test_dataset, model, f\"../models/checkpoints/model_checkpoint_utf8_{i}.pth\", 16))\n",
    "for _ in l1:\n",
    "    sum += _\n",
    "sum/len(l1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.645510650049228"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for _ in l1[1:]:\n",
    "    sum += _\n",
    "sum/(len(l1)-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.4017722066133564,\n 0.4640155608385563,\n 0.46271882429219796,\n 0.5076723578992868,\n 0.58288307758807,\n 0.6913767019667171,\n 0.7434622865787768,\n 0.7724227361141128,\n 0.7910092932785823,\n 0.7940350118867516]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
